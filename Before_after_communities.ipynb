{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.express as px\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Python SQLite Conversion Reader\n",
    "##################################\n",
    "last_db_path = None\n",
    "sql_columns = []\n",
    "\n",
    "class FromSQLite:\n",
    "    pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def infer_sql_type(dtype):\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            return \"INTEGER\"\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            return \"REAL\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            return \"DATETIME\"\n",
    "        else:\n",
    "            return \"TEXT\"  # Default to TEXT for other types\n",
    "\n",
    "    @staticmethod\n",
    "    def getData(SQL_columns='*', importer=None, exporter=None, year=None, product_code=None, value=None, quantity=None, table_name=\"base_data\", path=pathDB):\n",
    "        \"\"\"\n",
    "        Fetch data from SQLite with optional filters.\n",
    "\n",
    "        Args:\n",
    "            SQL_columns (str): Columns to select. Default is '*'.\n",
    "            importer (list, optional): List of import countries. Default is None.\n",
    "            exporter (list, optional): List of export countries. Default is None.\n",
    "            year (list, optional): List of years. Default is None.\n",
    "            product_code (list, optional): List of product codes. Default is None.\n",
    "            value (float, optional): Minimum value. Default is None.\n",
    "            quantity (float, optional): Minimum quantity. Default is None.\n",
    "            table_name (str, optional): Name of the table in the database. Default is \"base_data\".\n",
    "            path (str, optional): Path to the database file. Default is pathDB.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered data.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"ERROR: Database file '{path}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "        query = f\"SELECT {SQL_columns} FROM {table_name} WHERE 1=1\"\n",
    "        params = []\n",
    "        \n",
    "        if exporter:\n",
    "            print('Getting exporter', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in exporter)\n",
    "            query += f\" AND export_country IN ({placeholders})\"\n",
    "            params.extend(exporter)\n",
    "\n",
    "        if importer:\n",
    "            print('Getting importer', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in importer)\n",
    "            query += f\" AND import_country IN ({placeholders})\"\n",
    "            params.extend(importer)\n",
    "\n",
    "        if year:\n",
    "            print('Getting years', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in year)\n",
    "            query += f\" AND year IN ({placeholders})\"\n",
    "            params.extend(year)\n",
    "\n",
    "        if product_code:\n",
    "            print('Getting product codes', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in product_code)\n",
    "            query += f\" AND code IN ({placeholders})\"\n",
    "            params.extend(product_code)\n",
    "\n",
    "        if value:\n",
    "            print('Getting value', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in value)\n",
    "            query += f\" AND value IN ({placeholders})\"\n",
    "            params.append(value)\n",
    "\n",
    "        if quantity:\n",
    "            print('Getting quantity', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in quantity)\n",
    "            query += f\" AND quantity IN ({placeholders})\"\n",
    "            params.append(quantity)\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(path) as conn:\n",
    "                df = pd.read_sql_query(query, conn, params=params)\n",
    "        except sqlite3.OperationalError as e:\n",
    "            print(f\"SQL Error: {e}\")\n",
    "            return None\n",
    "\n",
    "        return df\n",
    "\n",
    "    def pushData(df, table_name='base_data', db_path=pathDB):\n",
    "        \"\"\"\n",
    "        Push data into SQLite database, adding only new rows and handling missing columns.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Data to push into the database.\n",
    "            table_name (str): Target table name.\n",
    "            db_path (str): Path to the SQLite database file.\n",
    "        \"\"\"\n",
    "        global last_db_path, sql_columns  # Declare global variables\n",
    "\n",
    "        db_path = db_path or FromSQLite.pathDB\n",
    "\n",
    "        # Ensure the directory for the database exists\n",
    "        if not os.path.exists(os.path.dirname(db_path)):\n",
    "            os.makedirs(os.path.dirname(db_path))\n",
    "\n",
    "        try:\n",
    "            # Connect to the SQLite database\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "                # Check if the table exists\n",
    "                cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "                table_exists = cursor.fetchone() is not None\n",
    "\n",
    "                if not table_exists:\n",
    "                    # Create the table with the DataFrame's schema\n",
    "                    print(f\"Table '{table_name}' does not exist. Creating it...\")\n",
    "                    df.head(0).to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "                # Check if the database path is the same as the last call\n",
    "                if db_path != last_db_path:\n",
    "                    # Cache the SQL column names for the table\n",
    "                    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "                    sql_columns = [row[1] for row in cursor.fetchall()]  # Get column names\n",
    "                    last_db_path = db_path\n",
    "\n",
    "                # Check for missing columns\n",
    "                df_columns = df.columns.tolist()\n",
    "                print(df_columns)\n",
    "                missing_in_sql = set(df_columns) - set(sql_columns)\n",
    "\n",
    "                # Add missing columns to the table if any\n",
    "                if missing_in_sql:\n",
    "                    for column in missing_in_sql:\n",
    "                        col_type = FromSQLite.infer_sql_type(df[column].dtype)\n",
    "                        cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column} {col_type};\")\n",
    "                    print(f\"Added missing columns: {missing_in_sql}\", end=\"\")\n",
    "\n",
    "                # Push data into the table\n",
    "                # Use pandas' `to_sql` with `if_exists='append'` to handle insertion\n",
    "                df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "                print(f\"Data successfully pushed to table '{table_name}'.\", end=\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error pushing data: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def updateData(table_name, updates, conditions, db_path=None):\n",
    "        \"\"\"\n",
    "        Update data in SQLite database based on conditions.\n",
    "        \"\"\"\n",
    "        db_path = db_path or os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                update_clause = ', '.join(f\"{k} = ?\" for k in updates.keys())\n",
    "                condition_clause = ' AND '.join(f\"{k} = ?\" for k in conditions.keys())\n",
    "                query = f\"UPDATE {table_name} SET {update_clause} WHERE {condition_clause}\"\n",
    "                params = list(updates.values()) + list(conditions.values())\n",
    "                cursor.execute(query, params)\n",
    "                conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating data: {e}\")\n",
    "\n",
    "    def summarize(db_path=pathDB):\n",
    "        # Get database size\n",
    "        db_size = os.path.getsize(db_path) / (1024 * 1024)\n",
    "        if db_size > 1000: \n",
    "            db_size /= 1024\n",
    "            print(f\"Database size: {db_size:.2f} GB\\n\")\n",
    "        else:\n",
    "            print(f\"Database size: {db_size:.2f} MB\\n\")\n",
    "\n",
    "        # Connect to the database\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # List all tables\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            tables = [row[0] for row in cursor.fetchall()]\n",
    "            print(\"Tables in the database:\")\n",
    "            print(tables, \"\\n\")\n",
    "\n",
    "            # Summarize each table\n",
    "            for table in tables:\n",
    "                print(f\"Summary for table '{table}':\")\n",
    "\n",
    "                # Get schema\n",
    "                cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "                schema = cursor.fetchall()\n",
    "                print(\"Schema:\")\n",
    "                for column in schema:\n",
    "                    print(f\"  {column}\")\n",
    "\n",
    "                # Get row count\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {table};\")\n",
    "                row_count = cursor.fetchone()[0]\n",
    "                print(f\"Row count: {row_count}\")\n",
    "\n",
    "                # Get sample data\n",
    "                try:\n",
    "                    # Random sample (5 rows)\n",
    "                    random_sample = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY RANDOM() LIMIT 5;\", conn)\n",
    "                    print(\"\\nRandom Sample:\")\n",
    "                    print(random_sample)\n",
    "\n",
    "                    # First 5 rows sorted by year\n",
    "                    first_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year ASC LIMIT 5;\", conn)\n",
    "                    print(\"\\nFirst 5 Rows by Year:\")\n",
    "                    print(first_by_year)\n",
    "\n",
    "                    # Last 5 rows sorted by year\n",
    "                    last_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year DESC LIMIT 5;\", conn)\n",
    "                    print(\"\\nLast 5 Rows by Year:\")\n",
    "                    print(last_by_year)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching sample data: {e}\")\n",
    "\n",
    "                print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Graph tool Constructor\n",
    "##################################\n",
    "class GraphConstructor():\n",
    "    def NX(df):\n",
    "        G = nx.MultiDiGraph()\n",
    "        for idx, row in df.iterrows():\n",
    "            try : \n",
    "                exporter = row['export_country']\n",
    "                importer = row['import_country']\n",
    "                product_code = row['code']\n",
    "                year = row['year']\n",
    "                quantity = row['quantity']\n",
    "            except Exception as e:\n",
    "                print(f'Could not extract data from the rows : {e}')\n",
    "                return\n",
    "        \n",
    "            G.add_node(exporter)\n",
    "            G.add_node(importer)\n",
    "\n",
    "            edge_key = (exporter, importer, year)\n",
    "\n",
    "            G.add_edge(\n",
    "                exporter,\n",
    "                importer,\n",
    "                key=edge_key,\n",
    "                year=year,\n",
    "                quantity=quantity\n",
    "            )\n",
    "        return G\n",
    "        \n",
    "        \n",
    "    def GT(df):\n",
    "        gtG = gt.Graph(directed=True)\n",
    "\n",
    "        # Create edge properties\n",
    "        eprop_exporter = gtG.new_edge_property(\"string\")\n",
    "        eprop_importer = gtG.new_edge_property(\"string\")\n",
    "        eprop_year = gtG.new_edge_property(\"float\")\n",
    "        eprop_product_code = gtG.new_edge_property(\"float\")\n",
    "        eprop_quantity = gtG.new_edge_property(\"float\")\n",
    "\n",
    "        # Create vertex properties\n",
    "        vertex_map = {}\n",
    "        vprop_country = gtG.new_vertex_property(\"string\")\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            try:\n",
    "                exporter = row['export_country']\n",
    "                importer = row['import_country']\n",
    "                product_code = row['code']\n",
    "                year = row['year']\n",
    "                quantity = row['quantity']\n",
    "            except Exception as e:\n",
    "                print(f\"Could not extract data from the rows: {e}\")\n",
    "                return None\n",
    "\n",
    "            # Add or retrieve exporter vertex\n",
    "            if exporter not in vertex_map:\n",
    "                v_exporter = gtG.add_vertex()\n",
    "                vertex_map[exporter] = v_exporter\n",
    "                vprop_country[v_exporter] = exporter\n",
    "\n",
    "            # Add or retrieve importer vertex\n",
    "            if importer not in vertex_map:\n",
    "                v_importer = gtG.add_vertex()\n",
    "                vertex_map[importer] = v_importer\n",
    "                vprop_country[v_importer] = importer\n",
    "\n",
    "            # Add edge between exporter and importer\n",
    "            e = gtG.add_edge(vertex_map[exporter], vertex_map[importer])\n",
    "\n",
    "            # Assign edge properties\n",
    "            eprop_exporter[e] = exporter\n",
    "            eprop_importer[e] = importer\n",
    "            eprop_year[e] = year\n",
    "            eprop_product_code[e] = product_code\n",
    "            eprop_quantity[e] = quantity\n",
    "\n",
    "        # Attach properties to the graph\n",
    "        gtG.vertex_properties[\"country\"] = vprop_country\n",
    "        gtG.edge_properties[\"exporter\"] = eprop_exporter\n",
    "        gtG.edge_properties[\"importer\"] = eprop_importer\n",
    "        gtG.edge_properties[\"year\"] = eprop_year\n",
    "        gtG.edge_properties[\"product_code\"] = eprop_product_code\n",
    "        gtG.edge_properties[\"quantity\"] = eprop_quantity\n",
    "\n",
    "        return gtG\n",
    "\n",
    "    \n",
    "#####################\n",
    "# VISUALIZER\n",
    "#####################\n",
    "class TradeNetworkVisualizer:\n",
    "    def __init__(self, product_graphs, dataframe):\n",
    "\n",
    "        self.product_graphs = product_graphs\n",
    "        self.dataframe = dataframe\n",
    "        self.world = gpd.read_file('https://naturalearth.s3.amazonaws.com/110m_cultural/ne_110m_admin_0_countries.zip')\n",
    "\n",
    "\n",
    "    def visualize_product_graph(self, product_code, year):\n",
    "        \"\"\"\n",
    "        Visualize the trade network graph for a specific product and year.\n",
    "    \n",
    "        This method extracts the edges corresponding to the given year from a product-specific\n",
    "        graph and visualizes the resulting trade network. If no data is available for the given\n",
    "        product or year, it prints a corresponding message.\n",
    "    \n",
    "        Args:\n",
    "            product_code (str): The code identifying the product whose trade network graph \n",
    "                is to be visualized.\n",
    "            year (int): The year for which the trade network is to be displayed.\n",
    "    \n",
    "        Returns:\n",
    "            None: Displays the trade network graph or prints an informational message \n",
    "            if no data is available.\n",
    "    \n",
    "        Raises:\n",
    "            None: This method does not raise exceptions but handles errors gracefully by \n",
    "            printing messages in cases where the graph or data for the specified year is missing.\n",
    "        \"\"\"\n",
    "        # Retrieve the graph for the given product code\n",
    "        gtG = self.product_graphs.get(product_code)\n",
    "        if gtG is None:\n",
    "            print(f\"No graph found for product {product_code}.\")\n",
    "            return\n",
    "    \n",
    "        # Retrieve edge and vertex properties\n",
    "        eprop_year = gtG.edge_properties.get(\"year\")\n",
    "        eprop_product_code = gtG.edge_properties.get(\"product_code\")\n",
    "        vprop_country = gtG.vertex_properties.get(\"country\")\n",
    "    \n",
    "        if not all([eprop_year, eprop_product_code, vprop_country]):\n",
    "            print(\"Required properties are missing in the graph.\")\n",
    "            return\n",
    "    \n",
    "        # Filter the graph for the given year and product\n",
    "        g_subgraph = gt.GraphView(\n",
    "            gtG, \n",
    "            efilt=lambda e: (eprop_year[e] == year) and (eprop_product_code[e] == product_code)\n",
    "        )\n",
    "    \n",
    "        if g_subgraph.num_edges() == 0:\n",
    "            print(f\"No trade data for product {product_code} in year {year}.\")\n",
    "            return\n",
    "    \n",
    "        # Compute the community structure using nested block model\n",
    "        state = gt.minimize_nested_blockmodel_dl(\n",
    "            g_subgraph, \n",
    "            state_args=dict(recs=[], rec_types=[]),\n",
    "            multilevel_mcmc_args=dict(niter=10)\n",
    "        )\n",
    "    \n",
    "        # Draw the hierarchical graph\n",
    "        gt.draw_hierarchy(\n",
    "            state,\n",
    "            vertex_text=g_subgraph.vertex_properties[\"country\"],\n",
    "            vsize_scale=5,\n",
    "            vertex_text_position=\"centered\",\n",
    "            layout=\"radial\",\n",
    "            deg_size=True,\n",
    "            rel_order=\"degree\",\n",
    "            output_size=(2000, 2000),\n",
    "            beta=0.9,\n",
    "        )\n",
    "        \n",
    "    def plot_trade_network(self, product_code, country_name, trade_type='export', figsize=(20, 15), export_to_png=False, export_file_name=\"\", percentile=1.0):\n",
    "        \"\"\"\n",
    "        Plots a trade network graph for a specific product code and either an export or import country.\n",
    "    \n",
    "        Nodes are weighted according to the share of total trade volume with the specified country.\n",
    "        Edges represent trade relationships, weighted by trade volume.\n",
    "    \n",
    "        Optionally, you can display only a specific percentile of trades based on trade volume.\n",
    "        For example, setting `percentile=0.5` will display only the largest 50% of all trades.\n",
    "    \n",
    "        Parameters:\n",
    "            product_code (str): The product code for which the trade network is to be plotted.\n",
    "            country_name (str): The name of the country (exporting or importing) to focus on.\n",
    "            trade_type (str, optional): 'export' to plot exports from the country, 'import' for imports into the country.\n",
    "                                        Defaults to 'export'.\n",
    "            figsize (tuple, optional): Figure size for the plot. Defaults to (20, 15).\n",
    "            export_to_png (bool, optional): If True, exports the plot to a PNG file. Defaults to False.\n",
    "            export_file_name (str, optional): Filename for the exported PNG. If not provided, a default name is generated.\n",
    "            percentile (float, optional): A value between 0 and 1 indicating the percentile of trades to display.\n",
    "                                          For example, 0.5 displays only the largest 50% of trades by volume.\n",
    "                                          Defaults to 1.0 (displays all trades).\n",
    "    \n",
    "        Returns:\n",
    "            None\n",
    "    \n",
    "        Displays a plot of the trade network or exports it to a PNG file if `export_to_png` is True.\n",
    "    \n",
    "        Notes:\n",
    "            - The function filters and aggregates trade data based on the provided `product_code` and `country_name`.\n",
    "            - Node sizes represent the trade volume share with the main country.\n",
    "            - Edge widths are proportional to the trade volume.\n",
    "            - If `percentile` is less than 1.0, only the largest trades (by volume) up to that percentile are displayed.\n",
    "            - This can be useful for focusing on the most significant trade relationships.\n",
    "    \n",
    "        Example:\n",
    "            To plot the largest 50% of export trades for product 'P123' from 'CountryA':\n",
    "    \n",
    "            ```python\n",
    "            plot_trade_network('P123', 'CountryA', trade_type='export', percentile=0.5)\n",
    "            ```\n",
    "        \"\"\"\n",
    "        dataframe = self.dataframe\n",
    "    \n",
    "        if trade_type == 'export':\n",
    "            filtered_data = dataframe[(dataframe.k == product_code) & (dataframe.export_country == country_name)]\n",
    "        elif trade_type == 'import':\n",
    "            filtered_data = dataframe[(dataframe.k == product_code) & (dataframe.import_country == country_name)]\n",
    "        else:\n",
    "            print(\"Invalid trade_type. Use 'export' or 'import'.\")\n",
    "            return\n",
    "    \n",
    "        if filtered_data.empty:\n",
    "            print(f\"No trade data found for product {product_code} and country {country_name}.\")\n",
    "            return\n",
    "    \n",
    "        total_volume = filtered_data['v'].sum()\n",
    "    \n",
    "        if total_volume == 0:\n",
    "            print(f\"No trade data found for product {product_code} and country {country_name}.\")\n",
    "            return\n",
    "    \n",
    "        filtered_data = filtered_data.sort_values(by='v', ascending=False)\n",
    "    \n",
    "        filtered_data['cumulative_v'] = filtered_data['v'].cumsum()\n",
    "        filtered_data['cumulative_percentage'] = filtered_data['cumulative_v'] / total_volume\n",
    "    \n",
    "        if percentile < 1.0:\n",
    "            filtered_data = filtered_data[filtered_data['cumulative_percentage'] <= percentile]\n",
    "            if filtered_data.empty:\n",
    "                print(f\"No trade data found within the top {percentile*100}% for product {product_code} and country {country_name}.\")\n",
    "                return\n",
    "    \n",
    "        total_volume_filtered = filtered_data['v'].sum()\n",
    "    \n",
    "        if trade_type == 'export':\n",
    "            volume_by_country = filtered_data.groupby('import_country')['v'].sum()\n",
    "        elif trade_type == 'import':\n",
    "            volume_by_country = filtered_data.groupby('export_country')['v'].sum()\n",
    "    \n",
    "        volume_by_country_share = (volume_by_country / total_volume_filtered).to_dict()\n",
    "    \n",
    "        G = nx.DiGraph()\n",
    "    \n",
    "        for _, row in filtered_data.iterrows():\n",
    "            G.add_edge(row['export_country'], row['import_country'], weight=row['v'])\n",
    "    \n",
    "        node_sizes = {}\n",
    "        node_colors = {}\n",
    "    \n",
    "        main_country_color = 'gold'\n",
    "        main_country_size = 2000\n",
    "    \n",
    "        partner_node_sizes = []\n",
    "    \n",
    "        for node in G.nodes():\n",
    "            if node == country_name:\n",
    "                node_sizes[node] = main_country_size\n",
    "                node_colors[node] = main_country_color\n",
    "            else:\n",
    "                share = volume_by_country_share.get(node, 0)\n",
    "                size = 1000 * share + 300\n",
    "                node_sizes[node] = size\n",
    "                partner_node_sizes.append(size)\n",
    "                node_colors[node] = None\n",
    "    \n",
    "        if partner_node_sizes:\n",
    "            cmap = cm.get_cmap('coolwarm')\n",
    "            norm = mcolors.Normalize(vmin=min(partner_node_sizes), vmax=max(partner_node_sizes))\n",
    "    \n",
    "            for node in G.nodes():\n",
    "                if node != country_name:\n",
    "                    node_colors[node] = cmap(norm(node_sizes[node]))\n",
    "        else:\n",
    "            for node in G.nodes():\n",
    "                if node != country_name:\n",
    "                    node_colors[node] = 'lightblue'\n",
    "    \n",
    "        edge_weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "        if edge_weights:\n",
    "            max_weight = max(edge_weights)\n",
    "            edge_widths = [5 * (w / max_weight) for w in edge_weights]\n",
    "        else:\n",
    "            edge_widths = []\n",
    "    \n",
    "        plt.figure(figsize=figsize)\n",
    "        pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)\n",
    "    \n",
    "        nx.draw_networkx_nodes(\n",
    "            G, pos,\n",
    "            node_size=[node_sizes[node] for node in G.nodes()],\n",
    "            node_color=[node_colors[node] for node in G.nodes()],\n",
    "            alpha=0.9\n",
    "        )\n",
    "    \n",
    "        nx.draw_networkx_edges(\n",
    "            G, pos, arrowstyle=\"->\", arrowsize=15, edge_color=\"gray\",\n",
    "            width=edge_widths, alpha=0.7\n",
    "        )\n",
    "    \n",
    "        nx.draw_networkx_labels(G, pos, font_size=12, font_weight=\"bold\")\n",
    "    \n",
    "        def format_volume(volume):\n",
    "            if volume >= 1e9:\n",
    "                return f'{volume / 1e9:.2f}B'\n",
    "            elif volume >= 1e6:\n",
    "                return f'{volume / 1e6:.2f}M'\n",
    "            elif volume >= 1e3:\n",
    "                return f'{volume / 1e3:.2f}K'\n",
    "            else:\n",
    "                return f'{volume}'\n",
    "    \n",
    "        edge_labels = {\n",
    "            (u, v): format_volume(G[u][v]['weight']) for u, v in G.edges()\n",
    "        }\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "        \n",
    "        product_title = filtered_data.description.unique()[0]\n",
    "        \n",
    "        title_trade = \"Exporting from\" if trade_type == 'export' else \"Importing into\"\n",
    "        plt.title(\n",
    "            f\"Trade Network for {product_title} - {title_trade} {country_name}\",\n",
    "            fontsize=15,\n",
    "            fontweight=\"bold\"\n",
    "        )\n",
    "    \n",
    "        if export_to_png:\n",
    "            if not export_file_name:\n",
    "                export_file_name = f\"trade_network_{product_code}_{country_name}_{trade_type}.png\"\n",
    "            plt.savefig(export_file_name, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def plot_trade_over_time(self, product_code, country_name, trade_type='export', figsize=(16, 8)):\n",
    "        \"\"\"\n",
    "        Plots the trade volume over time for a specific product code and country.\n",
    "    \n",
    "        The plot includes:\n",
    "        - The country's trade volume over time.\n",
    "        - The total global trade volume for the product over time.\n",
    "        - The country's relative share of the total trade volume over time.\n",
    "    \n",
    "        Args:\n",
    "            product_code (str): The product code for which the trade volume is to be plotted.\n",
    "            country_name (str): The name of the country to focus on (exporting or importing).\n",
    "            trade_type (str, optional): 'export' to show exports from the country, \n",
    "                                        'import' to show imports into the country. Defaults to 'export'.\n",
    "            figsize (tuple, optional): Size of the plot. Defaults to (12, 6).\n",
    "    \n",
    "        Returns:\n",
    "            None: Displays a line plot of the trade volume over time and the relative share over time.\n",
    "    \n",
    "        Notes:\n",
    "            - Filters the dataset to include only rows for the specified product code and trade type.\n",
    "            - Computes the country's trade volume over time.\n",
    "            - Computes the total global trade volume for the product over time.\n",
    "            - Calculates the country's relative share of the total trade volume over time.\n",
    "            - Displays a plot with two y-axes:\n",
    "                - Left y-axis: Trade volumes (country and total).\n",
    "                - Right y-axis: Relative share (%).\n",
    "            - Includes a legend to differentiate between the data series.\n",
    "        \"\"\"\n",
    "        dataframe = self.dataframe\n",
    "    \n",
    "        product_data = dataframe[dataframe['k'] == product_code]\n",
    "    \n",
    "        if product_data.empty:\n",
    "            print(f\"No trade data found for product {product_code}.\")\n",
    "            return\n",
    "    \n",
    "        total_trade_volume_over_time = product_data.groupby('t')['v'].sum().reset_index()\n",
    "    \n",
    "        if trade_type == 'export':\n",
    "            country_data = product_data[product_data['export_country'] == country_name]\n",
    "            \n",
    "        elif trade_type == 'import':\n",
    "            country_data = product_data[product_data['import_country'] == country_name]\n",
    "            \n",
    "        else:\n",
    "            print(\"Invalid trade_type. Use 'export' or 'import'.\")\n",
    "            return\n",
    "    \n",
    "        if country_data.empty:\n",
    "            print(f\"No trade data found for product {product_code} and country {country_name}.\")\n",
    "            return\n",
    "    \n",
    "        country_trade_volume_over_time = country_data.groupby('t')['v'].sum().reset_index()\n",
    "    \n",
    "        merged_data = pd.merge(\n",
    "            country_trade_volume_over_time, \n",
    "            total_trade_volume_over_time, \n",
    "            on='t', \n",
    "            how='right', \n",
    "            suffixes=('_country', '_total')\n",
    "        )\n",
    "    \n",
    "        merged_data['v_country'] = merged_data['v_country'].fillna(0)\n",
    "        merged_data['relative_share'] = (merged_data['v_country'] / merged_data['v_total']) * 100\n",
    "        merged_data.sort_values('t', inplace=True)\n",
    "    \n",
    "        fig, ax1 = plt.subplots(figsize=figsize)\n",
    "    \n",
    "        ax1.plot(\n",
    "            merged_data['t'], \n",
    "            merged_data['v_country'], \n",
    "            marker='o', \n",
    "            label=f\"{country_name} Trade Volume\", \n",
    "            color='tab:blue'\n",
    "        )\n",
    "        \n",
    "        ax1.plot(\n",
    "            merged_data['t'], \n",
    "            merged_data['v_total'], \n",
    "            marker='s', \n",
    "            label=\"Total Trade Volume\", \n",
    "            color='tab:green'\n",
    "        )\n",
    "        \n",
    "        ax1.set_xticks(merged_data['t'])\n",
    "        ax1.set_xticklabels(merged_data['t'].astype(int))\n",
    "        \n",
    "        ax1.set_xlabel('Year')\n",
    "        ax1.set_ylabel('Trade Volume (log)')\n",
    "        ax1.tick_params(axis='y')\n",
    "        ax1.grid(True)\n",
    "        ax1.set_yscale(\"log\")\n",
    "    \n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(\n",
    "            merged_data['t'], \n",
    "            merged_data['relative_share'], \n",
    "            marker='^', \n",
    "            label=f\"{country_name} Relative Share (%)\", \n",
    "            color='tab:red'\n",
    "        )\n",
    "        ax2.set_ylabel('Relative Share (%)')\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "    \n",
    "        lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "        lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "        ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
    "        \n",
    "        product_title = dataframe[dataframe.k == product_code].description.unique()[0]\n",
    "        \n",
    "        plt.title(f\"{product_title}\\n{trade_type.title()} by {country_name}\", fontweight=\"bold\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def plot_trade_treemap(self, product_code, year, trade_type='export', top_n=None, show_volumes=True, color_scale='Viridis'):\n",
    "        \"\"\"\n",
    "        Plots a treemap of trade volumes for a specific product code and year.\n",
    "    \n",
    "        This visualization helps analyze the trade relationships between countries for a given product,\n",
    "        highlighting the proportion of trade volumes in a hierarchical, space-filling manner.\n",
    "    \n",
    "        Args:\n",
    "            product_code (str): The product code for which the trade volumes are to be plotted.\n",
    "            year (int): The year for which the trade data is to be visualized.\n",
    "            trade_type (str, optional): 'export' to visualize exports from countries,\n",
    "                                        'import' to visualize imports into countries. Defaults to 'export'.\n",
    "            top_n (int, optional): The number of top country pairs by trade volume to display.\n",
    "                                   If None, includes all country pairs. Defaults to None.\n",
    "            show_volumes (bool, optional): If True, displays trade volumes on the treemap labels. Defaults to True.\n",
    "            color_scale (str, optional): The color scale to use for the treemap (e.g., 'Viridis', 'Cividis', 'Plasma'). Defaults to 'Viridis'.\n",
    "    \n",
    "        Returns:\n",
    "            None: Displays an interactive treemap of trade volumes with a dark background.\n",
    "    \n",
    "        Notes:\n",
    "            - **Data Filtering**: The dataset is filtered based on the provided product code and year.\n",
    "            - **Grouping**: Trade volumes are aggregated by export/import country pairs.\n",
    "            - **Top N Filtering**: If `top_n` is specified, only the top N country pairs by trade volume are displayed.\n",
    "            - **Color Scale Recalculation**: The color scale is automatically recalculated based on the filtered data.\n",
    "            - **Visualization**:\n",
    "                - Uses Plotly Express for interactive treemap visualization.\n",
    "                - Applies a dark theme (`'plotly_dark'`) for better visual appeal.\n",
    "                - Trade volumes are used both for sizing and coloring the rectangles.\n",
    "                - Hover information includes formatted trade volumes.\n",
    "            - **Customization**: Users can customize the color scale, adjust the plot size, and choose whether to display trade volumes on labels.\n",
    "            - **Search Functionality**: Allows users to highlight a specific country in the treemap.\n",
    "    \n",
    "        Example:\n",
    "            To plot an export treemap for product code 'P123' in year 2022, displaying the top 10 country pairs:\n",
    "    \n",
    "            ```python\n",
    "            plot_trade_treemap('P123', 2022, trade_type='export', top_n=10)\n",
    "            ```\n",
    "        \"\"\"\n",
    "        dataframe = self.dataframe\n",
    "    \n",
    "        if trade_type == 'export':\n",
    "            df_filtered = dataframe[(dataframe['k'] == product_code) & (dataframe['t'] == year)]\n",
    "            df_grouped = df_filtered.groupby(['export_country', 'import_country'])['v'].sum().reset_index()\n",
    "            path = ['export_country', 'import_country']\n",
    "            \n",
    "        elif trade_type == 'import':\n",
    "            df_filtered = dataframe[(dataframe['k'] == product_code) & (dataframe['t'] == year)]\n",
    "            df_grouped = df_filtered.groupby(['import_country', 'export_country'])['v'].sum().reset_index()\n",
    "            path = ['import_country', 'export_country']\n",
    "            \n",
    "        else:\n",
    "            return\n",
    "    \n",
    "        if df_grouped.empty:\n",
    "            return\n",
    "    \n",
    "        if top_n is not None:\n",
    "            df_grouped = df_grouped.nlargest(top_n, 'v')\n",
    "    \n",
    "        product_title = df_filtered['description'].unique()[0]\n",
    "    \n",
    "        fig = px.treemap(\n",
    "            df_grouped,\n",
    "            path=path,\n",
    "            values='v',\n",
    "            color='v',\n",
    "            color_continuous_scale=color_scale,\n",
    "            title=f'Trade Volume Treemap for \"{product_title}\" in {year} ({trade_type.title()})',\n",
    "            labels={'v': 'Trade Volume'},\n",
    "            hover_data={'v': ':,.2f'},\n",
    "        )\n",
    "    \n",
    "        fig.update_layout(\n",
    "            template='plotly_dark',\n",
    "            margin=dict(t=50, l=25, r=25, b=25),\n",
    "            height=800\n",
    "        )\n",
    "    \n",
    "        if show_volumes:\n",
    "            fig.data[0].textinfo = 'label+value+percent root'\n",
    "            fig.data[0].texttemplate = '<b>%{label}</b><br>Trade Volume: %{value:,.2f}<br>%{percentRoot:.2%} of Total Volume'\n",
    "            \n",
    "        else:\n",
    "            fig.data[0].textinfo = 'label+percent root'\n",
    "            fig.data[0].texttemplate = '<b>%{label}</b><br>%{percentRoot:.2%} of Total Volume'\n",
    "    \n",
    "        fig.update_coloraxes(colorbar_title='Trade Volume')\n",
    "        fig.update_traces(marker=dict(cornerradius=5))\n",
    "        \n",
    "        fig.show()\n",
    "            \n",
    "            \n",
    "    def visualize_trade_changes(self, year1: int, year2: int, trade_type: str, origin_country: str, hso_code: int):\n",
    "        \"\"\"\n",
    "        Visualize relative changes in trade volumes (imports or exports) between two years.\n",
    "    \n",
    "        Parameters:\n",
    "            year1 (int): Base year for comparison.\n",
    "            year2 (int): Target year for comparison.\n",
    "            trade_type (str): \"imports\" or \"exports\" to focus on trade direction.\n",
    "            origin_country (str): Country of focus (e.g., \"Russian Federation\").\n",
    "            hso_code (int): hso_code specifying the product (e.g., 853400 for semiconductors)\n",
    "        \n",
    "        Returns:\n",
    "            None. Displays a choropleth map of relative changes.\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.dataframe.copy(deep=True)\n",
    "        df = df[df.k == hso_code]\n",
    "        \n",
    "        if trade_type == \"exports\":\n",
    "            df_filtered = df[df['export_country'] == origin_country]\n",
    "            group_by_country = 'import_country'\n",
    "        elif trade_type == \"imports\":\n",
    "            df_filtered = df[df['import_country'] == origin_country]\n",
    "            group_by_country = 'export_country'\n",
    "        else:\n",
    "            raise ValueError(\"Invalid trade_type. Choose 'imports' or 'exports'.\")\n",
    "        \n",
    "        df_year1 = df_filtered[df_filtered['t'] == year1].groupby(group_by_country)['q'].sum().reset_index()\n",
    "        df_year2 = df_filtered[df_filtered['t'] == year2].groupby(group_by_country)['q'].sum().reset_index()\n",
    "    \n",
    "        df_year1.rename(columns={'q': f'quantity_{year1}'}, inplace=True)\n",
    "        df_year2.rename(columns={'q': f'quantity_{year2}'}, inplace=True)\n",
    "    \n",
    "        df_change = pd.merge(df_year1, df_year2, on=group_by_country, how='outer').fillna(0)\n",
    "    \n",
    "        df_change['relative_change'] = (df_change[f'quantity_{year2}'] - df_change[f'quantity_{year1}']) / \\\n",
    "                                       df_change[f'quantity_{year1}'].replace(0, np.nan)\n",
    "        df_change.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "        df_change[group_by_country] = df_change[group_by_country].replace({\n",
    "            'USA': 'United States',\n",
    "            'Republic of Korea': 'South Korea',\n",
    "            'Czechia': 'Czech Republic',\n",
    "            'Türkiye': 'Turkey',\n",
    "            'Viet Nam': 'Vietnam',\n",
    "            'United Kingdom of Great Britain and Northern Ireland': 'United Kingdom',\n",
    "            'Iran (Islamic Republic of)': 'Iran',\n",
    "            'Lao People\\'s Democratic Republic': 'Laos',\n",
    "            'Venezuela (Bolivarian Republic of)': 'Venezuela',\n",
    "            'Democratic Republic of the Congo': 'Democratic Republic of the Congo',\n",
    "        })\n",
    "    \n",
    "        world_merged = self.world.merge(df_change, how='left', left_on='NAME', right_on=group_by_country)\n",
    "    \n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    \n",
    "        world_merged.plot(\n",
    "            column='relative_change', \n",
    "            cmap='coolwarm', \n",
    "            linewidth=0.8, \n",
    "            ax=ax, \n",
    "            edgecolor='0.8', \n",
    "            legend=True, \n",
    "            cax=cax, \n",
    "            vmin=-1, \n",
    "            vmax=1,\n",
    "            missing_kwds={'color': 'lightgrey'}\n",
    "        )\n",
    "        ax.set_title(f\"Relative Change for {hso_code} in {trade_type.capitalize()} from {year1} to {year2} ({origin_country})\", fontweight=\"bold\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 282520"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m visualizer \u001b[38;5;241m=\u001b[39m TradeNetworkVisualizer(gtG, df)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m expanded_years:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mvisualizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_product_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 124\u001b[0m, in \u001b[0;36mTradeNetworkVisualizer.visualize_product_graph\u001b[0;34m(self, product_code, year)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mVisualize the trade network graph for a specific product and year.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    printing messages in cases where the graph or data for the specified year is missing.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Retrieve the graph for the given product code\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m gtG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproduct_graphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(product_code)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gtG \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo graph found for product \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# Anomaly Scores getting\n",
    "#########################\n",
    "pathDB = os.path.join(os.getcwd(), 'basedata','total_base_data.db')\n",
    "\n",
    "anomaly_score_path = os.path.join(os.getcwd(), 'full_reconstruction.csv')\n",
    "anomaly_scores = pd.read_csv(anomaly_score_path).drop(columns='Unnamed: 0')\n",
    "\n",
    "anomaly_scores.sort_values(by=['normalized_anomaly_score'],ascending=False, inplace=True)\n",
    "\n",
    "subsample = anomaly_scores.iloc[:10, :]\n",
    "\n",
    "for product_code in subsample['product']:\n",
    "    print(f'Starting {product_code}', end=\"\")\n",
    "    years = (\n",
    "        subsample[subsample['product'] == product_code]\n",
    "        .sort_values(by='year', ascending=True)['year']\n",
    "        .tolist()\n",
    "    )\n",
    "    expanded_years = []\n",
    "    for year in years:\n",
    "        expanded_years.extend(range(year - 1, year + 4))\n",
    "    expanded_years = sorted(set(expanded_years))\n",
    "\n",
    "    placeholders = ', '.join(str(year) for year in expanded_years)\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            import_country,\n",
    "            export_country,\n",
    "            quantity,\n",
    "            value,\n",
    "            year,\n",
    "            code\n",
    "        FROM\n",
    "            base_data\n",
    "        WHERE\n",
    "            year IN ({placeholders})\n",
    "            AND code = {product_code};\n",
    "    \"\"\"\n",
    "    with sqlite3.connect(pathDB) as conn:\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "    gtG = GraphConstructor.GT(df)\n",
    "    visualizer = TradeNetworkVisualizer(gtG, df)\n",
    "    for year in expanded_years:\n",
    "        visualizer.visualize_product_graph(product_code, year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 282520Starting 440729Starting 710900Starting 271600Starting 290541Starting 400280Starting 282520Starting 282200Starting 630790Starting 382312      product  year  anomaly_score  normalized_anomaly_score  num_edges\n",
      "150    282520  2022     187.730990                  4.868543        631\n",
      "1046   440729  2017      49.409870                  1.957534       2455\n",
      "1246   710900  2018      31.481358                  1.232855        584\n",
      "546    271600  2022       9.717204                  1.193504        452\n",
      "695    290541  2021       6.772557                  1.041737        457\n",
      "998    400280  2017      45.895750                  0.921439        591\n",
      "152    282520  2017      17.882095                  0.816563        573\n",
      "310    282200  2018      29.430801                  0.802520        694\n",
      "1185   630790  2020      62.755768                  0.731703      11538\n",
      "899    382312  2021       6.201731                  0.654457        720\n",
      "[2021]\n"
     ]
    }
   ],
   "source": [
    "pathDB = os.path.join(os.getcwd(), 'basedata','total_base_data.db')\n",
    "\n",
    "anomaly_score_path = os.path.join(os.getcwd(), 'full_reconstruction.csv')\n",
    "anomaly_scores = pd.read_csv(anomaly_score_path).drop(columns='Unnamed: 0')\n",
    "\n",
    "anomaly_scores.sort_values(by=['normalized_anomaly_score'],ascending=False, inplace=True)\n",
    "\n",
    "subsample = anomaly_scores.iloc[:10, :]\n",
    "for product_code in subsample['product']:\n",
    "    print(f'Starting {product_code}', end=\"\")\n",
    "    years = (\n",
    "        subsample[subsample['product'] == product_code]\n",
    "        .sort_values(by='year', ascending=True)['year']\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "print(subsample)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 12.71 GB\n",
      "\n",
      "Tables in the database:\n",
      "['base_data'] \n",
      "\n",
      "Summary for table 'base_data':\n",
      "Schema:\n",
      "  (0, 'year', 'INT', 0, None, 0)\n",
      "  (1, 'code', 'TEXT', 0, None, 0)\n",
      "  (2, 'value', 'REAL', 0, None, 0)\n",
      "  (3, 'quantity', 'REAL', 0, None, 0)\n",
      "  (4, 'export_country', 'TEXT', 0, None, 0)\n",
      "  (5, 'import_country', 'TEXT', 0, None, 0)\n",
      "Row count: 247174310\n",
      "\n",
      "Random Sample:\n",
      "   year    code    value  quantity export_country import_country\n",
      "0  2015  860721   94.637     5.224         Canada        Belgium\n",
      "1  2002  621210  148.437     2.699          Italy          China\n",
      "2  2011  902580    0.200     0.003        Belarus           Cuba\n",
      "3  2018  285100   12.996     4.449      Australia   Solomon Isds\n",
      "4  2001  282760    7.791     0.503          Spain      Venezuela\n",
      "\n",
      "First 5 Rows by Year:\n",
      "   year    code   value  quantity export_country import_country\n",
      "0  1995  841510  36.687     5.812    Afghanistan        Algeria\n",
      "1  1995  570110  11.060     0.195    Afghanistan        Andorra\n",
      "2  1995  080620  11.804    15.000    Afghanistan      Australia\n",
      "3  1995  570110  11.931     0.245    Afghanistan      Australia\n",
      "4  1995  570210   3.692     0.377    Afghanistan      Australia\n",
      "\n",
      "Last 5 Rows by Year:\n",
      "   year    code   value  quantity export_country import_country\n",
      "0  2022  210610   0.392     0.002    Afghanistan        Andorra\n",
      "1  2022  210690   0.068     0.001    Afghanistan        Andorra\n",
      "2  2022  271000   6.233     8.103    Afghanistan        Andorra\n",
      "3  2022  843131   0.352     0.022    Afghanistan        Andorra\n",
      "4  2022  071332  35.025    25.060    Afghanistan         Angola\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pathDB = os.path.join(os.getcwd(), 'basedata','total_base_data.db')\n",
    "FromSQLite.summarize(pathDB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TradeFlowProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
