{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import plotly.express as px\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import graph_tool.all as gt\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Python SQLite Conversion Reader\n",
    "##################################\n",
    "last_db_path = None\n",
    "sql_columns = []\n",
    "\n",
    "class FromSQLite:\n",
    "    pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def infer_sql_type(dtype):\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            return \"INTEGER\"\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            return \"REAL\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            return \"DATETIME\"\n",
    "        else:\n",
    "            return \"TEXT\"  # Default to TEXT for other types\n",
    "\n",
    "    @staticmethod\n",
    "    def getData(SQL_columns='*', importer=None, exporter=None, year=None, product_code=None, value=None, quantity=None, table_name=\"base_data\", path=pathDB):\n",
    "        \"\"\"\n",
    "        Fetch data from SQLite with optional filters.\n",
    "\n",
    "        Args:\n",
    "            SQL_columns (str): Columns to select. Default is '*'.\n",
    "            importer (list, optional): List of import countries. Default is None.\n",
    "            exporter (list, optional): List of export countries. Default is None.\n",
    "            year (list, optional): List of years. Default is None.\n",
    "            product_code (list, optional): List of product codes. Default is None.\n",
    "            value (float, optional): Minimum value. Default is None.\n",
    "            quantity (float, optional): Minimum quantity. Default is None.\n",
    "            table_name (str, optional): Name of the table in the database. Default is \"base_data\".\n",
    "            path (str, optional): Path to the database file. Default is pathDB.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered data.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"ERROR: Database file '{path}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "        query = f\"SELECT {SQL_columns} FROM {table_name} WHERE 1=1\"\n",
    "        params = []\n",
    "        \n",
    "        if exporter:\n",
    "            print('Getting exporter', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in exporter)\n",
    "            query += f\" AND export_country IN ({placeholders})\"\n",
    "            params.extend(exporter)\n",
    "\n",
    "        if importer:\n",
    "            print('Getting importer', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in importer)\n",
    "            query += f\" AND import_country IN ({placeholders})\"\n",
    "            params.extend(importer)\n",
    "\n",
    "        if year:\n",
    "            print('Getting years', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in year)\n",
    "            query += f\" AND year IN ({placeholders})\"\n",
    "            params.extend(year)\n",
    "\n",
    "        if product_code:\n",
    "            print('Getting product codes', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in product_code)\n",
    "            query += f\" AND code IN ({placeholders})\"\n",
    "            params.extend(product_code)\n",
    "\n",
    "        if value:\n",
    "            print('Getting value', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in value)\n",
    "            query += f\" AND value IN ({placeholders})\"\n",
    "            params.append(value)\n",
    "\n",
    "        if quantity:\n",
    "            print('Getting quantity', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in quantity)\n",
    "            query += f\" AND quantity IN ({placeholders})\"\n",
    "            params.append(quantity)\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(path) as conn:\n",
    "                df = pd.read_sql_query(query, conn, params=params)\n",
    "        except sqlite3.OperationalError as e:\n",
    "            print(f\"SQL Error: {e}\")\n",
    "            return None\n",
    "\n",
    "        return df\n",
    "\n",
    "    def pushData(df, table_name='base_data', db_path=pathDB):\n",
    "        \"\"\"\n",
    "        Push data into SQLite database, adding only new rows and handling missing columns.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Data to push into the database.\n",
    "            table_name (str): Target table name.\n",
    "            db_path (str): Path to the SQLite database file.\n",
    "        \"\"\"\n",
    "        global last_db_path, sql_columns  # Declare global variables\n",
    "\n",
    "        db_path = db_path or FromSQLite.pathDB\n",
    "\n",
    "        # Ensure the directory for the database exists\n",
    "        if not os.path.exists(os.path.dirname(db_path)):\n",
    "            os.makedirs(os.path.dirname(db_path))\n",
    "\n",
    "        try:\n",
    "            # Connect to the SQLite database\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "                # Check if the table exists\n",
    "                cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "                table_exists = cursor.fetchone() is not None\n",
    "\n",
    "                if not table_exists:\n",
    "                    # Create the table with the DataFrame's schema\n",
    "                    print(f\"Table '{table_name}' does not exist. Creating it...\")\n",
    "                    df.head(0).to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "                # Check if the database path is the same as the last call\n",
    "                if db_path != last_db_path:\n",
    "                    # Cache the SQL column names for the table\n",
    "                    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "                    sql_columns = [row[1] for row in cursor.fetchall()]  # Get column names\n",
    "                    last_db_path = db_path\n",
    "\n",
    "                # Check for missing columns\n",
    "                df_columns = df.columns.tolist()\n",
    "                print(df_columns)\n",
    "                missing_in_sql = set(df_columns) - set(sql_columns)\n",
    "\n",
    "                # Add missing columns to the table if any\n",
    "                if missing_in_sql:\n",
    "                    for column in missing_in_sql:\n",
    "                        col_type = FromSQLite.infer_sql_type(df[column].dtype)\n",
    "                        cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column} {col_type};\")\n",
    "                    print(f\"Added missing columns: {missing_in_sql}\", end=\"\")\n",
    "\n",
    "                # Push data into the table\n",
    "                # Use pandas' `to_sql` with `if_exists='append'` to handle insertion\n",
    "                df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "                print(f\"Data successfully pushed to table '{table_name}'.\", end=\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error pushing data: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def updateData(table_name, updates, conditions, db_path=None):\n",
    "        \"\"\"\n",
    "        Update data in SQLite database based on conditions.\n",
    "        \"\"\"\n",
    "        db_path = db_path or os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                update_clause = ', '.join(f\"{k} = ?\" for k in updates.keys())\n",
    "                condition_clause = ' AND '.join(f\"{k} = ?\" for k in conditions.keys())\n",
    "                query = f\"UPDATE {table_name} SET {update_clause} WHERE {condition_clause}\"\n",
    "                params = list(updates.values()) + list(conditions.values())\n",
    "                cursor.execute(query, params)\n",
    "                conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating data: {e}\")\n",
    "\n",
    "    def summarize(db_path=pathDB):\n",
    "        # Get database size\n",
    "        db_size = os.path.getsize(db_path) / (1024 * 1024)\n",
    "        if db_size > 1000: \n",
    "            db_size /= 1024\n",
    "            print(f\"Database size: {db_size:.2f} GB\\n\")\n",
    "        else:\n",
    "            print(f\"Database size: {db_size:.2f} MB\\n\")\n",
    "\n",
    "        # Connect to the database\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # List all tables\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            tables = [row[0] for row in cursor.fetchall()]\n",
    "            print(\"Tables in the database:\")\n",
    "            print(tables, \"\\n\")\n",
    "\n",
    "            # Summarize each table\n",
    "            for table in tables:\n",
    "                print(f\"Summary for table '{table}':\")\n",
    "\n",
    "                # Get schema\n",
    "                cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "                schema = cursor.fetchall()\n",
    "                print(\"Schema:\")\n",
    "                for column in schema:\n",
    "                    print(f\"  {column}\")\n",
    "\n",
    "                # Get row count\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {table};\")\n",
    "                row_count = cursor.fetchone()[0]\n",
    "                print(f\"Row count: {row_count}\")\n",
    "\n",
    "                # Get sample data\n",
    "                try:\n",
    "                    # Random sample (5 rows)\n",
    "                    random_sample = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY RANDOM() LIMIT 5;\", conn)\n",
    "                    print(\"\\nRandom Sample:\")\n",
    "                    print(random_sample)\n",
    "\n",
    "                    # First 5 rows sorted by year\n",
    "                    first_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year ASC LIMIT 5;\", conn)\n",
    "                    print(\"\\nFirst 5 Rows by Year:\")\n",
    "                    print(first_by_year)\n",
    "\n",
    "                    # Last 5 rows sorted by year\n",
    "                    last_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year DESC LIMIT 5;\", conn)\n",
    "                    print(\"\\nLast 5 Rows by Year:\")\n",
    "                    print(last_by_year)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching sample data: {e}\")\n",
    "\n",
    "                print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    year,\n",
    "    import_country,\n",
    "    export_country,\n",
    "    SUM(value) AS value\n",
    "FROM\n",
    "    base_data\n",
    "GROUP BY\n",
    "    year, import_country, export_country, code\n",
    "ORDER BY\n",
    "    year;\n",
    "\"\"\"\n",
    "\n",
    "with sqlite3.connect(pathDB) as conn:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TradeFlowProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
