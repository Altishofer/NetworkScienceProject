{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Python SQLite Conversion Reader\n",
    "##################################\n",
    "last_db_path = None\n",
    "sql_columns = []\n",
    "\n",
    "class FromSQLite:\n",
    "    pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def infer_sql_type(dtype):\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            return \"INTEGER\"\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            return \"REAL\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            return \"DATETIME\"\n",
    "        else:\n",
    "            return \"TEXT\"  # Default to TEXT for other types\n",
    "\n",
    "    @staticmethod\n",
    "    def getData(SQL_columns='*', importer=None, exporter=None, year=None, product_code=None, value=None, quantity=None, table_name=\"base_data\", path=pathDB):\n",
    "        \"\"\"\n",
    "        Fetch data from SQLite with optional filters.\n",
    "\n",
    "        Args:\n",
    "            SQL_columns (str): Columns to select. Default is '*'.\n",
    "            importer (list, optional): List of import countries. Default is None.\n",
    "            exporter (list, optional): List of export countries. Default is None.\n",
    "            year (list, optional): List of years. Default is None.\n",
    "            product_code (list, optional): List of product codes. Default is None.\n",
    "            value (float, optional): Minimum value. Default is None.\n",
    "            quantity (float, optional): Minimum quantity. Default is None.\n",
    "            table_name (str, optional): Name of the table in the database. Default is \"base_data\".\n",
    "            path (str, optional): Path to the database file. Default is pathDB.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered data.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"ERROR: Database file '{path}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "        query = f\"SELECT {SQL_columns} FROM {table_name} WHERE 1=1\"\n",
    "        params = []\n",
    "        \n",
    "        if exporter:\n",
    "            print('Getting exporter', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in exporter)\n",
    "            query += f\" AND export_country IN ({placeholders})\"\n",
    "            params.extend(exporter)\n",
    "\n",
    "        if importer:\n",
    "            print('Getting importer', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in importer)\n",
    "            query += f\" AND import_country IN ({placeholders})\"\n",
    "            params.extend(importer)\n",
    "\n",
    "        if year:\n",
    "            print('Getting years', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in year)\n",
    "            query += f\" AND year IN ({placeholders})\"\n",
    "            params.extend(year)\n",
    "\n",
    "        if product_code:\n",
    "            print('Getting product codes', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in product_code)\n",
    "            query += f\" AND code IN ({placeholders})\"\n",
    "            params.extend(product_code)\n",
    "\n",
    "        if value:\n",
    "            print('Getting value', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in value)\n",
    "            query += f\" AND value IN ({placeholders})\"\n",
    "            params.append(value)\n",
    "\n",
    "        if quantity:\n",
    "            print('Getting quantity', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in quantity)\n",
    "            query += f\" AND quantity IN ({placeholders})\"\n",
    "            params.append(quantity)\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(path) as conn:\n",
    "                df = pd.read_sql_query(query, conn, params=params)\n",
    "        except sqlite3.OperationalError as e:\n",
    "            print(f\"SQL Error: {e}\")\n",
    "            return None\n",
    "\n",
    "        return df\n",
    "\n",
    "    def pushData(df, table_name='base_data', db_path=pathDB):\n",
    "        \"\"\"\n",
    "        Push data into SQLite database, adding only new rows and handling missing columns.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Data to push into the database.\n",
    "            table_name (str): Target table name.\n",
    "            db_path (str): Path to the SQLite database file.\n",
    "        \"\"\"\n",
    "        global last_db_path, sql_columns  # Declare global variables\n",
    "\n",
    "        db_path = db_path or FromSQLite.pathDB\n",
    "\n",
    "        # Ensure the directory for the database exists\n",
    "        if not os.path.exists(os.path.dirname(db_path)):\n",
    "            os.makedirs(os.path.dirname(db_path))\n",
    "\n",
    "        try:\n",
    "            # Connect to the SQLite database\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "                # Check if the table exists\n",
    "                cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "                table_exists = cursor.fetchone() is not None\n",
    "\n",
    "                if not table_exists:\n",
    "                    # Create the table with the DataFrame's schema\n",
    "                    print(f\"Table '{table_name}' does not exist. Creating it...\")\n",
    "                    df.head(0).to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "                # Check if the database path is the same as the last call\n",
    "                if db_path != last_db_path:\n",
    "                    # Cache the SQL column names for the table\n",
    "                    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "                    sql_columns = [row[1] for row in cursor.fetchall()]  # Get column names\n",
    "                    last_db_path = db_path\n",
    "\n",
    "                # Check for missing columns\n",
    "                df_columns = df.columns.tolist()\n",
    "                print(df_columns)\n",
    "                missing_in_sql = set(df_columns) - set(sql_columns)\n",
    "\n",
    "                # Add missing columns to the table if any\n",
    "                if missing_in_sql:\n",
    "                    for column in missing_in_sql:\n",
    "                        col_type = FromSQLite.infer_sql_type(df[column].dtype)\n",
    "                        cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column} {col_type};\")\n",
    "                    print(f\"Added missing columns: {missing_in_sql}\", end=\"\")\n",
    "\n",
    "                # Push data into the table\n",
    "                # Use pandas' `to_sql` with `if_exists='append'` to handle insertion\n",
    "                df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "                print(f\"Data successfully pushed to table '{table_name}'.\", end=\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error pushing data: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def updateData(table_name, updates, conditions, db_path=None):\n",
    "        \"\"\"\n",
    "        Update data in SQLite database based on conditions.\n",
    "        \"\"\"\n",
    "        db_path = db_path or os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                update_clause = ', '.join(f\"{k} = ?\" for k in updates.keys())\n",
    "                condition_clause = ' AND '.join(f\"{k} = ?\" for k in conditions.keys())\n",
    "                query = f\"UPDATE {table_name} SET {update_clause} WHERE {condition_clause}\"\n",
    "                params = list(updates.values()) + list(conditions.values())\n",
    "                cursor.execute(query, params)\n",
    "                conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating data: {e}\")\n",
    "\n",
    "    def summarize(db_path=pathDB):\n",
    "        # Get database size\n",
    "        db_size = os.path.getsize(db_path) / (1024 * 1024)\n",
    "        if db_size > 1000: \n",
    "            db_size /= 1024\n",
    "            print(f\"Database size: {db_size:.2f} GB\\n\")\n",
    "        else:\n",
    "            print(f\"Database size: {db_size:.2f} MB\\n\")\n",
    "\n",
    "        # Connect to the database\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # List all tables\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            tables = [row[0] for row in cursor.fetchall()]\n",
    "            print(\"Tables in the database:\")\n",
    "            print(tables, \"\\n\")\n",
    "\n",
    "            # Summarize each table\n",
    "            for table in tables:\n",
    "                print(f\"Summary for table '{table}':\")\n",
    "\n",
    "                # Get schema\n",
    "                cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "                schema = cursor.fetchall()\n",
    "                print(\"Schema:\")\n",
    "                for column in schema:\n",
    "                    print(f\"  {column}\")\n",
    "\n",
    "                # Get row count\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {table};\")\n",
    "                row_count = cursor.fetchone()[0]\n",
    "                print(f\"Row count: {row_count}\")\n",
    "\n",
    "                # Get sample data\n",
    "                try:\n",
    "                    # Random sample (5 rows)\n",
    "                    random_sample = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY RANDOM() LIMIT 5;\", conn)\n",
    "                    print(\"\\nRandom Sample:\")\n",
    "                    print(random_sample)\n",
    "\n",
    "                    # First 5 rows sorted by year\n",
    "                    first_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year ASC LIMIT 5;\", conn)\n",
    "                    print(\"\\nFirst 5 Rows by Year:\")\n",
    "                    print(first_by_year)\n",
    "\n",
    "                    # Last 5 rows sorted by year\n",
    "                    last_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year DESC LIMIT 5;\", conn)\n",
    "                    print(\"\\nLast 5 Rows by Year:\")\n",
    "                    print(last_by_year)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching sample data: {e}\")\n",
    "\n",
    "                print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_file_processing(file, product_codes, country_codes, test = None):\n",
    "    file_path = os.path.join(os.getcwd(), \"dataset\", file)\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    df[\"k\"] = df[\"k\"].astype(str)  # Convert to string\n",
    "    product_codes[\"code\"] = product_codes[\"code\"].astype(str) \n",
    "    # First merge for column 'i'\n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=country_codes.rename(columns={\"country_code\": \"country_code_i\"}),\n",
    "        left_on=\"i\",\n",
    "        right_on=\"country_code_i\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"country_name\": \"export_country\", \"country_iso3\": \"export_country_iso3\"})\n",
    "\n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=country_codes.rename(columns={\"country_code\": \"country_code_j\"}),\n",
    "        left_on=\"j\",\n",
    "        right_on=\"country_code_j\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"country_name\": \"import_country\", \"country_iso3\": \"import_country_iso3\", \"t\": \"year\", \"k\":\"code\", \"v\":\"value\", \"q\":\"quantity\"}).drop(\n",
    "        columns=[\"country_iso2_x\", \"country_iso2_y\", \"country_code_i\", \"country_code_j\", \"i\", \"j\",\"export_country_iso3\",\"import_country_iso3\"], axis=1\n",
    "    )\n",
    "\n",
    "    if df is None:\n",
    "        print(f\"Skipping file: {file}\")\n",
    "        return None\n",
    "    \n",
    "    if test:\n",
    "        return df\n",
    "    else:\n",
    "        FromSQLite.pushData(df)\n",
    "        print(f'{file} succesfully pushed to SQLite', end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed file\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "# SQLite Import/Export Processing\n",
    "#################################\n",
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "if os.path.exists(pathDB):\n",
    "    print(\"Loading precomputed file\")\n",
    "    # df = FromSQLite.getData()\n",
    "    \n",
    "else:\n",
    "    files_to_process = [\n",
    "        file for file in os.listdir(os.path.join(os.getcwd(), \"dataset\"))\n",
    "        if file.startswith(\"BACI_\") and file.endswith(\".csv\")\n",
    "    ]\n",
    "    print(files_to_process, end=\"\")\n",
    "\n",
    "    country_codes = pd.read_csv(os.path.join(\"dataset\", \"country_codes_V202401b.csv\"))\n",
    "    product_codes = pd.read_csv(os.path.join(\"dataset\", \"product_codes_HS22_V202401b.csv\"))\n",
    "\n",
    "    Parallel(n_jobs=1, backend='loky')(\n",
    "        delayed(lambda file : FromSQLite.pushData(whole_file_processing(file, product_codes, country_codes), table_name=\"base_data\", db_path=pathDB))\n",
    "        (file) for file in files_to_process\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading precomputed file\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# SQLite Gravity Processing\n",
    "###########################\n",
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"gravity.db\")\n",
    "if os.path.exists(pathDB):\n",
    "    print(\"Loading precomputed file\")\n",
    "    # df = FromSQLite.getData()\n",
    "    \n",
    "else:\n",
    "    \"\"\"\n",
    "    files_to_process = [\n",
    "        file for file in os.listdir(os.path.join(os.getcwd(), \"gravity\"))\n",
    "        if file.startswith(\"BACI_\") and file.endswith(\".csv\")\n",
    "    ]\n",
    "    \"\"\"\n",
    "    gravity_path = os.path.join(os.getcwd(), \"gravity\", \"Gravity_V202211.csv\")\n",
    "    gravity_df = pd.read_csv(gravity_path)\n",
    "\n",
    "    FromSQLite.pushData(gravity_df, db_path=pathDB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Cleanup the mess of a SQL table\n",
    "##################################\n",
    "\n",
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "conn = sqlite3.connect(pathDB)\n",
    "cursor = conn.cursor()\n",
    "# Execute the update query\n",
    "cursor.execute(\"\"\"\n",
    "    UPDATE base_data\n",
    "    SET code = printf('%06d', code)\n",
    "    WHERE LENGTH(code) < 6;\n",
    "\"\"\")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 12.71 GB\n",
      "\n",
      "Tables in the database:\n",
      "['base_data'] \n",
      "\n",
      "Summary for table 'base_data':\n",
      "Schema:\n",
      "  (0, 'year', 'INT', 0, None, 0)\n",
      "  (1, 'code', 'TEXT', 0, None, 0)\n",
      "  (2, 'value', 'REAL', 0, None, 0)\n",
      "  (3, 'quantity', 'REAL', 0, None, 0)\n",
      "  (4, 'export_country', 'TEXT', 0, None, 0)\n",
      "  (5, 'import_country', 'TEXT', 0, None, 0)\n",
      "Row count: 247174310\n",
      "\n",
      "Random Sample:\n",
      "   year    code   value  quantity export_country import_country\n",
      "0  2003  701890  43.889     1.500         Israel        Austria\n",
      "1  2021  480441   1.626     0.129          China         France\n",
      "2  2002  220190   3.292     8.889      Australia          China\n",
      "3  2011  521132   0.161     0.025     Bangladesh        Czechia\n",
      "4  2007  560900   6.596     2.502     Costa Rica      Nicaragua\n",
      "\n",
      "First 5 Rows by Year:\n",
      "   year    code   value  quantity export_country import_country\n",
      "0  1995  841510  36.687     5.812    Afghanistan        Algeria\n",
      "1  1995  570110  11.060     0.195    Afghanistan        Andorra\n",
      "2  1995  080620  11.804    15.000    Afghanistan      Australia\n",
      "3  1995  570110  11.931     0.245    Afghanistan      Australia\n",
      "4  1995  570210   3.692     0.377    Afghanistan      Australia\n",
      "\n",
      "Last 5 Rows by Year:\n",
      "   year    code   value  quantity export_country import_country\n",
      "0  2022  210610   0.392     0.002    Afghanistan        Andorra\n",
      "1  2022  210690   0.068     0.001    Afghanistan        Andorra\n",
      "2  2022  271000   6.233     8.103    Afghanistan        Andorra\n",
      "3  2022  843131   0.352     0.022    Afghanistan        Andorra\n",
      "4  2022  071332  35.025    25.060    Afghanistan         Angola\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "FromSQLite.summarize(pathDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Aggregate Category\n",
    "##################################\n",
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    year,\n",
    "    import_country,\n",
    "    export_country,\n",
    "    SUBSTR('00000' || CAST(code AS TEXT), -6, 2) AS code,\n",
    "    SUM(value) AS value,\n",
    "    SUM(quantity) AS quantity,\n",
    "    COUNT(DISTINCT code) AS distinct_products\n",
    "FROM\n",
    "    base_data\n",
    "GROUP BY\n",
    "    year, import_country, export_country, code\n",
    "ORDER BY\n",
    "    year;\n",
    "\"\"\"\n",
    "with sqlite3.connect(pathDB) as conn:\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FromSQLite.pushData(df, table_name='aggregate 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Database cleanup\n",
    "############################ \n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(pathDB)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Add a new column\n",
    "cursor.execute(\"ALTER TABLE base_data ADD COLUMN value_real REAL\")\n",
    "\n",
    "# Update the new column with converted values\n",
    "cursor.execute(\"UPDATE base_data SET value_real = CAST(value AS REAL)\")\n",
    "\n",
    "# Rename the column (workaround for SQLite's limitation)\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE base_data_new AS\n",
    "    SELECT \n",
    "        year,\n",
    "        code,\n",
    "        value,\n",
    "        quantity_real AS quantity,\n",
    "        export_country,\n",
    "        import_country\n",
    "    FROM base_data\n",
    "\"\"\")\n",
    "\n",
    "# Drop the old table\n",
    "cursor.execute(\"DROP TABLE base_data\")\n",
    "\n",
    "# Rename the new table\n",
    "cursor.execute(\"ALTER TABLE base_data_new RENAME TO base_data\")\n",
    "\n",
    "# Commit and close\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TradeFlowProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
