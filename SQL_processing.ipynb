{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Python SQLite Conversion Reader\n",
    "##################################\n",
    "last_db_path = None\n",
    "sql_columns = []\n",
    "\n",
    "class FromSQLite:\n",
    "    pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def infer_sql_type(dtype):\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            return \"INTEGER\"\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            return \"REAL\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            return \"DATETIME\"\n",
    "        else:\n",
    "            return \"TEXT\"  # Default to TEXT for other types\n",
    "\n",
    "    @staticmethod\n",
    "    def getData(SQL_columns='*', importer=None, exporter=None, year=None, product_code=None, value=None, quantity=None, table_name=\"base_data\", path=pathDB):\n",
    "        \"\"\"\n",
    "        Fetch data from SQLite with optional filters.\n",
    "\n",
    "        Args:\n",
    "            SQL_columns (str): Columns to select. Default is '*'.\n",
    "            importer (list, optional): List of import countries. Default is None.\n",
    "            exporter (list, optional): List of export countries. Default is None.\n",
    "            year (list, optional): List of years. Default is None.\n",
    "            product_code (list, optional): List of product codes. Default is None.\n",
    "            value (float, optional): Minimum value. Default is None.\n",
    "            quantity (float, optional): Minimum quantity. Default is None.\n",
    "            table_name (str, optional): Name of the table in the database. Default is \"base_data\".\n",
    "            path (str, optional): Path to the database file. Default is pathDB.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered data.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"ERROR: Database file '{path}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "        query = f\"SELECT {SQL_columns} FROM {table_name} WHERE 1=1\"\n",
    "        params = []\n",
    "        \n",
    "        if exporter:\n",
    "            print('Getting exporter', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in exporter)\n",
    "            query += f\" AND export_country IN ({placeholders})\"\n",
    "            params.extend(exporter)\n",
    "\n",
    "        if importer:\n",
    "            print('Getting importer', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in importer)\n",
    "            query += f\" AND import_country IN ({placeholders})\"\n",
    "            params.extend(importer)\n",
    "\n",
    "        if year:\n",
    "            print('Getting years', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in year)\n",
    "            query += f\" AND year IN ({placeholders})\"\n",
    "            params.extend(year)\n",
    "\n",
    "        if product_code:\n",
    "            print('Getting product codes', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in product_code)\n",
    "            query += f\" AND code IN ({placeholders})\"\n",
    "            params.extend(product_code)\n",
    "\n",
    "        if value:\n",
    "            print('Getting value', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in value)\n",
    "            query += f\" AND value IN ({placeholders})\"\n",
    "            params.append(value)\n",
    "\n",
    "        if quantity:\n",
    "            print('Getting quantity', end=\"\")\n",
    "            placeholders = ', '.join('?' for _ in quantity)\n",
    "            query += f\" AND quantity IN ({placeholders})\"\n",
    "            params.append(quantity)\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(path) as conn:\n",
    "                df = pd.read_sql_query(query, conn, params=params)\n",
    "        except sqlite3.OperationalError as e:\n",
    "            print(f\"SQL Error: {e}\")\n",
    "            return None\n",
    "\n",
    "        return df\n",
    "\n",
    "    def pushData(df, table_name='base_data', db_path=pathDB):\n",
    "        \"\"\"\n",
    "        Push data into SQLite database, adding only new rows and handling missing columns.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Data to push into the database.\n",
    "            table_name (str): Target table name.\n",
    "            db_path (str): Path to the SQLite database file.\n",
    "        \"\"\"\n",
    "        global last_db_path, sql_columns  # Declare global variables\n",
    "\n",
    "        db_path = db_path or FromSQLite.pathDB\n",
    "\n",
    "        # Ensure the directory for the database exists\n",
    "        if not os.path.exists(os.path.dirname(db_path)):\n",
    "            os.makedirs(os.path.dirname(db_path))\n",
    "\n",
    "        try:\n",
    "            # Connect to the SQLite database\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "                # Check if the table exists\n",
    "                cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "                table_exists = cursor.fetchone() is not None\n",
    "\n",
    "                if not table_exists:\n",
    "                    # Create the table with the DataFrame's schema\n",
    "                    print(f\"Table '{table_name}' does not exist. Creating it...\")\n",
    "                    df.head(0).to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "                # Check if the database path is the same as the last call\n",
    "                if db_path != last_db_path:\n",
    "                    # Cache the SQL column names for the table\n",
    "                    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "                    sql_columns = [row[1] for row in cursor.fetchall()]  # Get column names\n",
    "                    last_db_path = db_path\n",
    "\n",
    "                # Check for missing columns\n",
    "                df_columns = df.columns.tolist()\n",
    "                print(df_columns)\n",
    "                missing_in_sql = set(df_columns) - set(sql_columns)\n",
    "\n",
    "                # Add missing columns to the table if any\n",
    "                if missing_in_sql:\n",
    "                    for column in missing_in_sql:\n",
    "                        col_type = FromSQLite.infer_sql_type(df[column].dtype)\n",
    "                        cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column} {col_type};\")\n",
    "                    print(f\"Added missing columns: {missing_in_sql}\", end=\"\")\n",
    "\n",
    "                # Push data into the table\n",
    "                # Use pandas' `to_sql` with `if_exists='append'` to handle insertion\n",
    "                df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "                print(f\"Data successfully pushed to table '{table_name}'.\", end=\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error pushing data: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def updateData(table_name, updates, conditions, db_path=None):\n",
    "        \"\"\"\n",
    "        Update data in SQLite database based on conditions.\n",
    "        \"\"\"\n",
    "        db_path = db_path or os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                update_clause = ', '.join(f\"{k} = ?\" for k in updates.keys())\n",
    "                condition_clause = ' AND '.join(f\"{k} = ?\" for k in conditions.keys())\n",
    "                query = f\"UPDATE {table_name} SET {update_clause} WHERE {condition_clause}\"\n",
    "                params = list(updates.values()) + list(conditions.values())\n",
    "                cursor.execute(query, params)\n",
    "                conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating data: {e}\")\n",
    "\n",
    "    def summarize(db_path=pathDB):\n",
    "        # Get database size\n",
    "        db_size = os.path.getsize(db_path) / (1024 * 1024)\n",
    "        if db_size > 1000: \n",
    "            db_size /= 1024\n",
    "            print(f\"Database size: {db_size:.2f} GB\\n\")\n",
    "        else:\n",
    "            print(f\"Database size: {db_size:.2f} MB\\n\")\n",
    "\n",
    "        # Connect to the database\n",
    "        with sqlite3.connect(db_path) as conn:\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # List all tables\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            tables = [row[0] for row in cursor.fetchall()]\n",
    "            print(\"Tables in the database:\")\n",
    "            print(tables, \"\\n\")\n",
    "\n",
    "            # Summarize each table\n",
    "            for table in tables:\n",
    "                print(f\"Summary for table '{table}':\")\n",
    "\n",
    "                # Get schema\n",
    "                cursor.execute(f\"PRAGMA table_info({table});\")\n",
    "                schema = cursor.fetchall()\n",
    "                print(\"Schema:\")\n",
    "                for column in schema:\n",
    "                    print(f\"  {column}\")\n",
    "\n",
    "                # Get row count\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {table};\")\n",
    "                row_count = cursor.fetchone()[0]\n",
    "                print(f\"Row count: {row_count}\")\n",
    "\n",
    "                # Get sample data\n",
    "                try:\n",
    "                    # Random sample (5 rows)\n",
    "                    random_sample = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY RANDOM() LIMIT 5;\", conn)\n",
    "                    print(\"\\nRandom Sample:\")\n",
    "                    print(random_sample)\n",
    "\n",
    "                    # First 5 rows sorted by year\n",
    "                    first_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year ASC LIMIT 5;\", conn)\n",
    "                    print(\"\\nFirst 5 Rows by Year:\")\n",
    "                    print(first_by_year)\n",
    "\n",
    "                    # Last 5 rows sorted by year\n",
    "                    last_by_year = pd.read_sql_query(f\"SELECT * FROM {table} ORDER BY year DESC LIMIT 5;\", conn)\n",
    "                    print(\"\\nLast 5 Rows by Year:\")\n",
    "                    print(last_by_year)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error fetching sample data: {e}\")\n",
    "\n",
    "                print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_file_processing(file, product_codes, country_codes, test = None):\n",
    "    file_path = os.path.join(os.getcwd(), \"dataset\", file)\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    df[\"k\"] = df[\"k\"].astype(str)  # Convert to string\n",
    "    product_codes[\"code\"] = product_codes[\"code\"].astype(str) \n",
    "    # First merge for column 'i'\n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=country_codes.rename(columns={\"country_code\": \"country_code_i\"}),\n",
    "        left_on=\"i\",\n",
    "        right_on=\"country_code_i\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"country_name\": \"export_country\", \"country_iso3\": \"export_country_iso3\"})\n",
    "\n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=country_codes.rename(columns={\"country_code\": \"country_code_j\"}),\n",
    "        left_on=\"j\",\n",
    "        right_on=\"country_code_j\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"country_name\": \"import_country\", \"country_iso3\": \"import_country_iso3\", \"t\": \"year\", \"k\":\"code\", \"v\":\"value\", \"q\":\"quantity\"}).drop(\n",
    "        columns=[\"country_iso2_x\", \"country_iso2_y\", \"country_code_i\", \"country_code_j\", \"i\", \"j\",\"export_country_iso3\",\"import_country_iso3\"], axis=1\n",
    "    )\n",
    "\n",
    "    if df is None:\n",
    "        print(f\"Skipping file: {file}\")\n",
    "        return None\n",
    "    \n",
    "    if test:\n",
    "        return df\n",
    "    else:\n",
    "        FromSQLite.pushData(df)\n",
    "        print(f'{file} succesfully pushed to SQLite', end=\"\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BACI_HS92_Y2009_V202401b.csv', 'BACI_HS92_Y2008_V202401b.csv', 'BACI_HS92_Y2010_V202401b.csv', 'BACI_HS92_Y2017_V202401b.csv', 'BACI_HS92_Y2002_V202401b.csv', 'BACI_HS92_Y2005_V202401b.csv', 'BACI_HS92_Y1996_V202401b.csv', 'BACI_HS92_Y2021_V202401b.csv', 'BACI_HS92_Y2004_V202401b.csv', 'BACI_HS92_Y2003_V202401b.csv', 'BACI_HS92_Y2016_V202401b.csv', 'BACI_HS92_Y2011_V202401b.csv', 'BACI_HS92_Y2020_V202401b.csv', 'BACI_HS92_Y1997_V202401b.csv', 'BACI_HS92_Y2001_V202401b.csv', 'BACI_HS92_Y2006_V202401b.csv', 'BACI_HS92_Y2013_V202401b.csv', 'BACI_HS92_Y2014_V202401b.csv', 'BACI_HS92_Y2022_V202401b.csv', 'BACI_HS92_Y1995_V202401b.csv', 'BACI_HS92_Y2015_V202401b.csv', 'BACI_HS92_Y2012_V202401b.csv', 'BACI_HS92_Y2007_V202401b.csv', 'BACI_HS92_Y2000_V202401b.csv', 'BACI_HS92_Y1999_V202401b.csv', 'BACI_HS92_Y2018_V202401b.csv', 'BACI_HS92_Y1998_V202401b.csv', 'BACI_HS92_Y2019_V202401b.csv']Table 'base_data' does not exist. Creating it...\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2009_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2008_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2010_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2017_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2002_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2005_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y1996_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2021_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2004_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2003_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2016_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2011_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2020_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y1997_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2001_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2006_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2013_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2014_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2022_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y1995_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2015_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2012_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2007_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2000_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y1999_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2018_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y1998_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n",
      "['year', 'code', 'value', 'quantity', 'export_country', 'import_country']\n",
      "Data successfully pushed to table 'base_data'.BACI_HS92_Y2019_V202401b.csv succesfully pushed to SQLiteError pushing data: 'NoneType' object has no attribute 'columns'\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# SQLite Processing\n",
    "#####################\n",
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "if os.path.exists(pathDB):\n",
    "    print(\"Loading precomputed file\")\n",
    "    # df = FromSQLite.getData()\n",
    "    \n",
    "else:\n",
    "    files_to_process = [\n",
    "        file for file in os.listdir(os.path.join(os.getcwd(), \"dataset\"))\n",
    "        if file.startswith(\"BACI_\") and file.endswith(\".csv\")\n",
    "    ]\n",
    "    print(files_to_process, end=\"\")\n",
    "\n",
    "    country_codes = pd.read_csv(os.path.join(\"dataset\", \"country_codes_V202401b.csv\"))\n",
    "    product_codes = pd.read_csv(os.path.join(\"dataset\", \"product_codes_HS22_V202401b.csv\"))\n",
    "\n",
    "    Parallel(n_jobs=1, backend='loky')(\n",
    "        delayed(lambda file : FromSQLite.pushData(whole_file_processing(file, product_codes, country_codes), table_name=\"base_data\", db_path=pathDB))\n",
    "        (file) for file in files_to_process\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x105924eb0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/TradeFlowProject/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "result_df = FromSQLite.getData(\n",
    "    SQL_columns='year, import_country, export_country'\n",
    ")\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size: 13.95 GB\n",
      "\n",
      "Tables in the database:\n",
      "['base_data'] \n",
      "\n",
      "Summary for table 'base_data':\n",
      "Schema:\n",
      "  (0, 'year', 'INTEGER', 0, None, 0)\n",
      "  (1, 'code', 'TEXT', 0, None, 0)\n",
      "  (2, 'value', 'REAL', 0, None, 0)\n",
      "  (3, 'quantity', 'TEXT', 0, None, 0)\n",
      "  (4, 'export_country', 'TEXT', 0, None, 0)\n",
      "  (5, 'import_country', 'TEXT', 0, None, 0)\n",
      "Row count: 247174310\n",
      "\n",
      "Random Sample:\n",
      "   year    code    value       quantity  export_country import_country\n",
      "0  2016  691110    6.666          6.302          Panama           Cuba\n",
      "1  1997  820590   21.739          2.187  United Kingdom        Iceland\n",
      "2  2011  391310    0.090          0.009             USA  FS Micronesia\n",
      "3  2009  360300  775.127         40.552    South Africa         Sweden\n",
      "4  2019  910229    2.192          0.010           Japan       Slovakia\n",
      "\n",
      "First 5 Rows by Year:\n",
      "   year    code   value       quantity export_country import_country\n",
      "0  1995  841510  36.687          5.812    Afghanistan        Algeria\n",
      "1  1995  570110  11.060          0.195    Afghanistan        Andorra\n",
      "2  1995   80620  11.804         15.000    Afghanistan      Australia\n",
      "3  1995  570110  11.931          0.245    Afghanistan      Australia\n",
      "4  1995  570210   3.692          0.377    Afghanistan      Australia\n",
      "\n",
      "Last 5 Rows by Year:\n",
      "   year    code   value       quantity export_country import_country\n",
      "0  2022  210610   0.392          0.002    Afghanistan        Andorra\n",
      "1  2022  210690   0.068          0.001    Afghanistan        Andorra\n",
      "2  2022  271000   6.233          8.103    Afghanistan        Andorra\n",
      "3  2022  843131   0.352          0.022    Afghanistan        Andorra\n",
      "4  2022   71332  35.025         25.060    Afghanistan         Angola\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FromSQLite.summarize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Sample:\n",
      "   year    code  value       quantity export_country import_country\n",
      "0  2009  570500  1.322          0.045    Afghanistan        Albania\n",
      "1  2009   80620  1.098          1.910    Afghanistan        Algeria\n",
      "2  2009   81350  0.538          0.500    Afghanistan        Algeria\n",
      "3  2009  121190  6.183         10.250    Afghanistan        Algeria\n",
      "4  2009  491199  0.017          0.030    Afghanistan        Algeria\n",
      "\n",
      "Random Sample:\n",
      "   year    code     value       quantity  export_country import_country\n",
      "0  2006  284321     6.672          0.363           Italy          Spain\n",
      "1  1997  710691  2049.385             NA         Finland        Germany\n",
      "2  2000  851531   104.910          5.742         Denmark       Malaysia\n",
      "3  1998  843110    47.000          5.250         Germany      Sri Lanka\n",
      "4  2021  200580     1.119          0.320  United Kingdom           Oman\n",
      "\n",
      "First 5 Rows by Year:\n",
      "   year    code   value       quantity export_country import_country\n",
      "0  1995  841510  36.687          5.812    Afghanistan        Algeria\n",
      "1  1995  570110  11.060          0.195    Afghanistan        Andorra\n",
      "2  1995   80620  11.804         15.000    Afghanistan      Australia\n",
      "3  1995  570110  11.931          0.245    Afghanistan      Australia\n",
      "4  1995  570210   3.692          0.377    Afghanistan      Australia\n",
      "\n",
      "Last 5 Rows by Year:\n",
      "   year    code   value       quantity export_country import_country\n",
      "0  2022  210610   0.392          0.002    Afghanistan        Andorra\n",
      "1  2022  210690   0.068          0.001    Afghanistan        Andorra\n",
      "2  2022  271000   6.233          8.103    Afghanistan        Andorra\n",
      "3  2022  843131   0.352          0.022    Afghanistan        Andorra\n",
      "4  2022   71332  35.025         25.060    Afghanistan         Angola\n"
     ]
    }
   ],
   "source": [
    "table_name = \"base_data\"\n",
    "with sqlite3.connect(pathDB) as conn:\n",
    "    # Default sample (first 5 rows)\n",
    "    default_sample = pd.read_sql_query(f\"SELECT * FROM {table_name} LIMIT 5;\", conn)\n",
    "    print(\"Default Sample:\")\n",
    "    print(default_sample)\n",
    "\n",
    "    # Random sample (5 rows)\n",
    "    random_sample = pd.read_sql_query(f\"SELECT * FROM {table_name} ORDER BY RANDOM() LIMIT 5;\", conn)\n",
    "    print(\"\\nRandom Sample:\")\n",
    "    print(random_sample)\n",
    "\n",
    "    # First 5 rows sorted by year\n",
    "    first_by_year = pd.read_sql_query(f\"SELECT * FROM {table_name} ORDER BY year ASC LIMIT 5;\", conn)\n",
    "    print(\"\\nFirst 5 Rows by Year:\")\n",
    "    print(first_by_year)\n",
    "\n",
    "    # Last 5 rows sorted by year\n",
    "    last_by_year = pd.read_sql_query(f\"SELECT * FROM {table_name} ORDER BY year DESC LIMIT 5;\", conn)\n",
    "    print(\"\\nLast 5 Rows by Year:\")\n",
    "    print(last_by_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TradeFlowProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
