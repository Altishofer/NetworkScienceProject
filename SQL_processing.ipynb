{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "# Python SQLite Conversion Reader\n",
    "##################################\n",
    "last_db_path = None\n",
    "sql_columns = []\n",
    "\n",
    "class FromSQLite:\n",
    "    pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def infer_sql_type(dtype):\n",
    "        if pd.api.types.is_integer_dtype(dtype):\n",
    "            return \"INTEGER\"\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            return \"REAL\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            return \"DATETIME\"\n",
    "        else:\n",
    "            return \"TEXT\"  # Default to TEXT for other types\n",
    "\n",
    "    @staticmethod\n",
    "    def getData(SQL_columns='*', importer=None, exporter=None, year=None, product_code=None, value=None, quantity=None, table_name=\"base_data\", path=pathDB):\n",
    "        \"\"\"\n",
    "        Fetch data from SQLite with optional filters.\n",
    "\n",
    "        Args:\n",
    "            SQL_columns (str): Columns to select. Default is '*'.\n",
    "            importer (list, optional): List of import countries. Default is None.\n",
    "            exporter (list, optional): List of export countries. Default is None.\n",
    "            year (list, optional): List of years. Default is None.\n",
    "            product_code (list, optional): List of product codes. Default is None.\n",
    "            value (float, optional): Minimum value. Default is None.\n",
    "            quantity (float, optional): Minimum quantity. Default is None.\n",
    "            table_name (str, optional): Name of the table in the database. Default is \"base_data\".\n",
    "            path (str, optional): Path to the database file. Default is pathDB.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered data.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"ERROR: Database file '{path}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "        query = f\"SELECT {SQL_columns} FROM {table_name} WHERE 1=1\"\n",
    "        params = []\n",
    "\n",
    "        if exporter:\n",
    "            placeholders = ', '.join('?' for _ in exporter)\n",
    "            query += f\" AND export_country IN ({placeholders})\"\n",
    "            params.extend(exporter)\n",
    "\n",
    "        if importer:\n",
    "            placeholders = ', '.join('?' for _ in importer)\n",
    "            query += f\" AND import_country IN ({placeholders})\"\n",
    "            params.extend(importer)\n",
    "\n",
    "        if year:\n",
    "            placeholders = ', '.join('?' for _ in year)\n",
    "            query += f\" AND year IN ({placeholders})\"\n",
    "            params.extend(year)\n",
    "\n",
    "        if product_code:\n",
    "            placeholders = ', '.join('?' for _ in product_code)\n",
    "            query += f\" AND code IN ({placeholders})\"\n",
    "            params.extend(product_code)\n",
    "\n",
    "        if value:\n",
    "            placeholders = ', '.join('?' for _ in value)\n",
    "            query += f\" AND value IN ({placeholders})\"\n",
    "            params.append(value)\n",
    "\n",
    "        if quantity:\n",
    "            placeholders = ', '.join('?' for _ in quantity)\n",
    "            query += f\" AND quantity IN ({placeholders})\"\n",
    "            params.append(quantity)\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(path) as conn:\n",
    "                df = pd.read_sql_query(query, conn, params=params)\n",
    "        except sqlite3.OperationalError as e:\n",
    "            print(f\"SQL Error: {e}\")\n",
    "            return None\n",
    "\n",
    "        return df\n",
    "\n",
    "    def pushData(df, table_name='base_data', db_path=pathDB):\n",
    "        \"\"\"\n",
    "        Push data into SQLite database, adding only new rows and handling missing columns.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Data to push into the database.\n",
    "            table_name (str): Target table name.\n",
    "            db_path (str): Path to the SQLite database file.\n",
    "        \"\"\"\n",
    "        global last_db_path, sql_columns  # Declare global variables\n",
    "\n",
    "        db_path = db_path or FromSQLite.pathDB\n",
    "\n",
    "        # Ensure the directory for the database exists\n",
    "        if not os.path.exists(os.path.dirname(db_path)):\n",
    "            os.makedirs(os.path.dirname(db_path))\n",
    "\n",
    "        try:\n",
    "            # Connect to the SQLite database\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "\n",
    "                # Check if the table exists\n",
    "                cursor.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "                table_exists = cursor.fetchone() is not None\n",
    "\n",
    "                if not table_exists:\n",
    "                    # Create the table with the DataFrame's schema\n",
    "                    print(f\"Table '{table_name}' does not exist. Creating it...\")\n",
    "                    df.head(0).to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "                # Check if the database path is the same as the last call\n",
    "                if db_path != last_db_path:\n",
    "                    # Cache the SQL column names for the table\n",
    "                    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "                    sql_columns = [row[1] for row in cursor.fetchall()]  # Get column names\n",
    "                    last_db_path = db_path\n",
    "\n",
    "                # Check for missing columns\n",
    "                df_columns = df.columns.tolist()\n",
    "                print(df_columns)\n",
    "                missing_in_sql = set(df_columns) - set(sql_columns)\n",
    "\n",
    "                # Add missing columns to the table if any\n",
    "                if missing_in_sql:\n",
    "                    for column in missing_in_sql:\n",
    "                        col_type = FromSQLite.infer_sql_type(df[column].dtype)\n",
    "                        cursor.execute(f\"ALTER TABLE {table_name} ADD COLUMN {column} {col_type};\")\n",
    "                    print(f\"Added missing columns: {missing_in_sql}\", end=\"\")\n",
    "\n",
    "                # Push data into the table\n",
    "                # Use pandas' `to_sql` with `if_exists='append'` to handle insertion\n",
    "                df.to_sql(table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "                print(f\"Data successfully pushed to table '{table_name}'.\", end=\"\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error pushing data: {e}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def updateData(table_name, updates, conditions, db_path=None):\n",
    "        \"\"\"\n",
    "        Update data in SQLite database based on conditions.\n",
    "        \"\"\"\n",
    "        db_path = db_path or os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "\n",
    "        try:\n",
    "            with sqlite3.connect(db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                update_clause = ', '.join(f\"{k} = ?\" for k in updates.keys())\n",
    "                condition_clause = ' AND '.join(f\"{k} = ?\" for k in conditions.keys())\n",
    "                query = f\"UPDATE {table_name} SET {update_clause} WHERE {condition_clause}\"\n",
    "                params = list(updates.values()) + list(conditions.values())\n",
    "                cursor.execute(query, params)\n",
    "                conn.commit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_file_processing(file, product_codes, country_codes, test = None):\n",
    "    file_path = os.path.join(os.getcwd(), \"dataset\", file)\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    df[\"k\"] = df[\"k\"].astype(str)  # Convert to string\n",
    "    product_codes[\"code\"] = product_codes[\"code\"].astype(str) \n",
    "    # First merge for column 'i'\n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=country_codes.rename(columns={\"country_code\": \"country_code_i\"}),\n",
    "        left_on=\"i\",\n",
    "        right_on=\"country_code_i\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"country_name\": \"export_country\", \"country_iso3\": \"export_country_iso3\"})\n",
    "\n",
    "    df = pd.merge(\n",
    "        left=df,\n",
    "        right=country_codes.rename(columns={\"country_code\": \"country_code_j\"}),\n",
    "        left_on=\"j\",\n",
    "        right_on=\"country_code_j\",\n",
    "        how=\"left\"\n",
    "    ).rename(columns={\"country_name\": \"import_country\", \"country_iso3\": \"import_country_iso3\", \"t\": \"year\", \"k\":\"code\", \"v\":\"value\", \"q\":\"quantity\"}).drop(\n",
    "        columns=[\"country_iso2_x\", \"country_iso2_y\", \"country_code_i\", \"country_code_j\", \"i\", \"j\",\"export_country_iso3\",\"import_country_iso3\"], axis=1\n",
    "    )\n",
    "\n",
    "    if df is None:\n",
    "        print(f\"Skipping file: {file}\")\n",
    "        return None\n",
    "    \n",
    "    if test:\n",
    "        return df\n",
    "    else:\n",
    "        FromSQLite.pushData(df)\n",
    "        print(f'{file} succesfully pushed to SQLite', end=\"\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# SQLite Processing\n",
    "#####################\n",
    "pathDB = os.path.join(os.getcwd(), \"basedata\", \"total_base_data.db\")\n",
    "if os.path.exists(pathDB):\n",
    "    print(\"Loading precomputed file\")\n",
    "    df = FromSQLite.getData()\n",
    "    \n",
    "else:\n",
    "    files_to_process = [\n",
    "        file for file in os.listdir(os.path.join(os.getcwd(), \"dataset\"))\n",
    "        if file.startswith(\"BACI_\") and file.endswith(\".csv\")\n",
    "    ]\n",
    "    print(files_to_process, end=\"\")\n",
    "\n",
    "    country_codes = pd.read_csv(os.path.join(\"dataset\", \"country_codes_V202401b.csv\"))\n",
    "    product_codes = pd.read_csv(os.path.join(\"dataset\", \"product_codes_HS22_V202401b.csv\"))\n",
    "\n",
    "    Parallel(n_jobs=1, backend='loky')(\n",
    "        delayed(lambda file : FromSQLite.pushData(whole_file_processing(file, product_codes, country_codes), table_name=\"base_data\", db_path=pathDB))\n",
    "        (file) for file in files_to_process\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
